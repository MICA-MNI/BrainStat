{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTutorial 02: Context Decoding\n=========================================\n\nIn this tutorial you will learn about the context decoding tools included with\nBrainStat. The context decoding module consists of three parts: genetic\ndecoding, meta-analytic decoding and histological comparisons. Before we start,\nlets run a linear model testing for the effects of age on cortical thickness as\nwe did in Tutorial 1. We'll use the results of this model later in this\ntutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.datasets import fetch_mask, fetch_template_surface\nfrom brainstat.stats.SLM import SLM\nfrom brainstat.stats.terms import FixedEffect, MixedEffect\nfrom brainstat.tutorial.utils import fetch_mics_data\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nthickness, demographics = fetch_mics_data()\nmask = fetch_mask(\"fsaverage5\")\n\nterm_age = FixedEffect(demographics.AGE_AT_SCAN)\nterm_sex = FixedEffect(demographics.SEX)\nterm_subject = MixedEffect(demographics.SUB_ID)\nmodel = term_age + term_sex + term_age * term_sex + term_subject\n\ncontrast_age = -model.mean.AGE_AT_SCAN\nslm = SLM(\n    model,\n    contrast_age,\n    surf=\"fsaverage5\",\n    mask=mask,\n    correction=[\"fdr\", \"rft\"],\n    two_tailed=False,\n    cluster_threshold=0.01,\n)\nslm.fit(thickness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Genetics\n--------\n\nFor genetic decoding we use the Allen Human Brain Atlas through the abagen\ntoolbox. Note that abagen only accepts parcellated data. Here is a minimal\nexample of how we use abagen to get the genetic expression of the 100 regions\nof the Schaefer atlas and how to plot this expression to a matrix. Please note\nthat downloading the dataset and running this analysis can take several\nminutes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom brainspace.utils.parcellation import reduce_by_labels\nfrom matplotlib.cm import get_cmap\n\nfrom brainstat.context.genetics import surface_genetic_expression\nfrom brainstat.datasets import fetch_parcellation\n\n# Get Schaefer-100 genetic expression.\nschaefer_100_fs5 = fetch_parcellation(\"fsaverage5\", \"schaefer\", 100)\nsurfaces = fetch_template_surface(\"fsaverage5\", join=False)\nexpression = surface_genetic_expression(schaefer_100_fs5, surfaces, space=\"fsaverage\")\n\n# Plot Schaefer-100 genetic expression matrix.\ncolormap = copy.copy(get_cmap())\ncolormap.set_bad(color=\"black\")\nplt.imshow(expression, aspect=\"auto\", cmap=colormap)\nplt.colorbar().ax.tick_params(labelsize=14)\nplt.xticks(fontsize=14, rotation=45)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Gene Index\", fontdict={\"fontsize\": 16})\nplt.ylabel(\"Schaefer 100 Regions\", fontdict={\"fontsize\": 16})\nplt.gcf().subplots_adjust(bottom=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expression is a pandas DataFrame which shows the genetic expression of genes\nwithin each region of the atlas. By default, the values will fall in the range\n[0, 1] where higher values represent higher expression. However, if you change\nthe normalization function then this may change. Some regions may return NaN\nvalues for all genes. This occurs when there are no samples within this\nregion across all donors. We've denoted this region with the black color in the\nmatrix. By default, BrainStat uses all the default abagen parameters. If you wish to\ncustomize these parameters then the keyword arguments can be passed directly\nto `surface_genetic_expression`. For a full list of these arguments and their\nfunction please consult the abagen documentation.\n\nNext, lets have a look at the correlation between one gene (WFDC1) and our\nt-statistic map. Lets also plot the expression of this gene to the surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot correlation with WFDC1 gene\nt_stat_schaefer_100 = reduce_by_labels(slm.t.flatten(), schaefer_100_fs5)[1:]\n\ndf = pd.DataFrame({\"x\": t_stat_schaefer_100, \"y\": expression[\"WFDC1\"]})\ndf.dropna(inplace=True)\nplt.scatter(df.x, df.y, s=20, c=\"k\")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"t-statistic\", fontdict={\"fontsize\": 16})\nplt.ylabel(\"WFDC1 expression\", fontdict={\"fontsize\": 16})\nplt.plot(np.unique(df.x), np.poly1d(np.polyfit(df.x, df.y, 1))(np.unique(df.x)), \"k\")\nplt.text(-1.0, 0.75, f\"r={df.x.corr(df.y):.2f}\", fontdict={\"size\": 14})\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot WFDC1 gene to the surface.\nfrom brainspace.plotting.surface_plotting import plot_hemispheres\nfrom brainspace.utils.parcellation import map_to_labels\n\nvertexwise_WFDC1 = map_to_labels(\n    expression[\"WFDC1\"].to_numpy(),\n    schaefer_100_fs5,\n    mask=schaefer_100_fs5 != 0,\n    fill=np.nan,\n)\n\nplot_hemispheres(\n    surfaces[0],\n    surfaces[1],\n    vertexwise_WFDC1,\n    color_bar=True,\n    embed_nb=True,\n    size=(1400, 200),\n    zoom=1.45,\n    nan_color=(0.7, 0.7, 0.7, 1),\n    cb__labelTextProperty={\"fontSize\": 12},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find a small correlation. To test for significance we'll have\nto do some additional corrections, but more on that later.\n\nMeta-Analytic\n-------------\nTo perform meta-analytic decoding, BrainStat uses precomputed Neurosynth maps.\nHere we test which terms are most associated with a map of cortical thickness.\nA simple example analysis can be run as follows. The surface decoder\ninterpolates the data from the surface to the voxels in the volume that are in\nbetween the two input surfaces. We'll decode the t-statistics derived with our model\nearlier. Note that downloading the dataset and running this analysis can take several minutes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.context.meta_analysis import meta_analytic_decoder\n\nmeta_analysis = meta_analytic_decoder(\"fsaverage5\", slm.t.flatten())\nprint(meta_analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "meta_analysis now contains a pandas.dataFrame with the correlation values for\neach requested feature. Next we could create a Wordcloud of the included terms,\nwherein larger words denote higher correlations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n\nwc = WordCloud(background_color=\"white\", random_state=0)\nwc.generate_from_frequencies(frequencies=meta_analysis.to_dict()[\"Pearson's r\"])\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, we can visualize the top correlation values and associated terms\nin a radar plot, as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.context.meta_analysis import radar_plot\n\nnumFeat = 8\ndata = meta_analysis.to_numpy()[:numFeat]\nlabel = meta_analysis.index[:numFeat]\nradar_plot(data, label=label, axis_range=(0.18, 0.22))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we broadly summarize, we see a lot of words related to language e.g.,\n\"language comprehension\", \"broca\", \"speaking\", \"speech production\".\nGenerally you'll also find several hits related to anatomy or clinical conditions.\nDepending on your research question, it may be more interesting to\nselect only those terms related to cognition or some other subset.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Histological decoding\n---------------------\nFor histological decoding we use microstructural profile covariance gradients,\nas first shown by (Paquola et al, 2019, Plos Biology), computed from the\nBigBrain dataset. Firstly, lets download the MPC data, compute and plot its\ngradients, and correlate the first gradient with our t-statistic map.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.context.histology import (\n    compute_histology_gradients,\n    compute_mpc,\n    read_histology_profile,\n)\n\n# Run the analysis\nschaefer_400 = fetch_parcellation(\"fsaverage5\", \"schaefer\", 400)\nhistology_profiles = read_histology_profile(template=\"fsaverage5\")\nmpc = compute_mpc(histology_profiles, labels=schaefer_400)\ngradient_map = compute_histology_gradients(mpc, random_state=0)\n\n# Bring parcellated data to vertex data.\nvertexwise_gradient = map_to_labels(\n    gradient_map.gradients_[:, 0],\n    schaefer_400,\n    mask=schaefer_400 != 0,\n    fill=np.nan,\n)\n\nplot_hemispheres(\n    surfaces[0],\n    surfaces[1],\n    vertexwise_gradient,\n    embed_nb=True,\n    nan_color=(0.7, 0.7, 0.7, 1),\n    size=(1400, 200),\n    zoom=1.45,\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot the correlation between the t-stat\nt_stat_schaefer_400 = reduce_by_labels(slm.t.flatten(), schaefer_400)[1:]\ndf = pd.DataFrame({\"x\": t_stat_schaefer_400, \"y\": gradient_map.gradients_[:, 0]})\ndf.dropna(inplace=True)\nplt.scatter(df.x, df.y, s=5, c=\"k\")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"t-statistic\", fontdict={\"fontsize\": 16})\nplt.ylabel(\"MPC Gradient 1\", fontdict={\"fontsize\": 16})\nplt.plot(np.unique(df.x), np.poly1d(np.polyfit(df.x, df.y, 1))(np.unique(df.x)), \"k\")\nplt.text(2.3, 0.1, f\"r={df.x.corr(df.y):.2f}\", fontdict={\"size\": 14})\nplt.gcf().subplots_adjust(left=0.15)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The variable histology_profiles now contains histological profiles sampled at\n50 different depths across the cortex, mpc contains the covariance of these\nprofiles, and gradient_map contains their gradients. We also see that the\ncorrelation between our t-statistic map and these gradients is not very\nhigh. Depending on your use-case, each of the three variables here could be of\ninterest, but for purposes of this tutorial we'll plot the gradients to the\nsurface with BrainSpace. For details on what the GradientMaps class\n(gradient_map) contains please consult the BrainSpace documentation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainspace.utils.parcellation import map_to_labels\n\nsurfaces = fetch_template_surface(\"fsaverage5\", join=False)\n\n# Bring parcellated data to vertex data.\nvertexwise_data = []\nfor i in range(0, 2):\n    vertexwise_data.append(\n        map_to_labels(\n            gradient_map.gradients_[:, i],\n            schaefer_400,\n            mask=schaefer_400 != 0,\n            fill=np.nan,\n        )\n    )\n\n# Plot to surface.\nplot_hemispheres(\n    surfaces[0],\n    surfaces[1],\n    vertexwise_data,\n    embed_nb=True,\n    label_text=[\"Gradient 1\", \"Gradient 2\"],\n    color_bar=True,\n    size=(1400, 400),\n    zoom=1.45,\n    nan_color=(0.7, 0.7, 0.7, 1),\n    cb__labelTextProperty={\"fontSize\": 12},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we no longer use the y-axis regression used in (Paquola et al, 2019,\nPlos Biology), as such the first gradient becomes an anterior-posterior\ngradient.\n\nResting-state contextualization\n-------------------------------\nLastly, BrainStat provides contextualization using resting-state fMRI markers:\nspecifically, with the Yeo functional networks (Yeo et al., 2011, Journal of\nNeurophysiology), a clustering of resting-state connectivity, and the\nfunctional gradients (Margulies et al., 2016, PNAS), a lower dimensional\nmanifold of resting-state connectivity.\n\nAs an example, lets have a look at the the t-statistic map within the Yeo\nnetworks. We'll plot the Yeo networks as well as a barplot showing the mean\nand standard error of the mean within each network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.datasets import fetch_yeo_networks_metadata\n\nyeo_networks = fetch_parcellation(\"fsaverage5\", \"yeo\", 7)\nnetwork_names, yeo_colormap = fetch_yeo_networks_metadata(7)\n\nplot_hemispheres(\n    surfaces[0],\n    surfaces[1],\n    yeo_networks,\n    embed_nb=True,\n    cmap=\"yeo7\",\n    nan_color=(0.7, 0.7, 0.7, 1),\n    size=(1400, 200),\n    zoom=1.45,\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom scipy.stats import sem\n\nfrom brainstat.context.resting import yeo_networks_associations\n\nyeo_tstat_mean = yeo_networks_associations(slm.t.flatten(), \"fsaverage5\")\nyeo_tstat_sem = yeo_networks_associations(\n    slm.t.flatten(),\n    \"fsaverage5\",\n    reduction_operation=lambda x, y: sem(x, nan_policy=\"omit\"),\n)\n\nplt.bar(\n    np.arange(7),\n    yeo_tstat_mean[:, 0],\n    yerr=yeo_tstat_sem.flatten(),\n    color=yeo_colormap,\n    error_kw={\"elinewidth\": 5},\n)\nplt.xticks(np.arange(7), network_names, rotation=90, fontsize=14)\nplt.yticks(fontsize=14)\nplt.ylabel(\"t-statistic\", fontdict={\"fontsize\": 16})\nplt.gcf().subplots_adjust(left=0.2, bottom=0.5)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Across all networks, the mean t-statistic appears to be negative, with the\nmost negative values in the dorsal attnetion and visual networks.\n\nLastly, lets plot the functional gradients and have a look at their correlation\nwith our t-map.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainstat.datasets import fetch_gradients\n\nfunctional_gradients = fetch_gradients(\"fsaverage5\", \"margulies2016\")\n\n\nplot_hemispheres(\n    surfaces[0],\n    surfaces[1],\n    functional_gradients[:, 0:3].T,\n    color_bar=True,\n    label_text=[\"Gradient 1\", \"Gradient 2\", \"Gradient 3\"],\n    embed_nb=True,\n    size=(1400, 600),\n    zoom=1.45,\n    nan_color=(0.7, 0.7, 0.7, 1),\n    cb__labelTextProperty={\"fontSize\": 12},\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\"x\": slm.t.flatten(), \"y\": functional_gradients[:, 0]})\ndf.dropna(inplace=True)\nplt.scatter(df.x, df.y, s=0.01, c=\"k\")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"t-statistic\", fontdict={\"fontsize\": 16})\nplt.ylabel(\"Functional Gradient 1\", fontdict={\"fontsize\": 16})\nplt.plot(np.unique(df.x), np.poly1d(np.polyfit(df.x, df.y, 1))(np.unique(df.x)), \"k\")\nplt.text(-4.0, 6, f\"r={df.x.corr(df.y):.2f}\", fontdict={\"size\": 14})\nplt.gcf().subplots_adjust(left=0.2)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems the correlations are quite low. However, we'll need some more complex\ntests to assess statistical significance. There are many ways to compare these\ngradients to cortical markers. In general, we recommend using corrections for\nspatial autocorrelation which are implemented in BrainSpace. We'll show a\ncorrection with spin test in this tutorial; for other methods and further\ndetails please consult the BrainSpace tutorials.\n\nIn a spin test we compare the empirical correlation between the gradient and\nthe cortical marker to a distribution of correlations derived from data\nrotated across the cortical surface. The p-value then depends on the\npercentile of the empirical correlation within the permuted distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainspace.null_models import SpinPermutations\n\nsphere_left, sphere_right = fetch_template_surface(\n    \"fsaverage5\", layer=\"sphere\", join=False\n)\ntstat = slm.t.flatten()\ntstat_left = tstat[: slm.t.size // 2]\ntstat_right = tstat[slm.t.size // 2 :]\n\n# Run spin test with 1000 permutations.\nn_rep = 1000\nsp = SpinPermutations(n_rep=n_rep, random_state=2021)\nsp.fit(sphere_left, points_rh=sphere_right)\ntstat_rotated = np.hstack(sp.randomize(tstat_left, tstat_right))\n\n# Compute correlation for empirical and permuted data.\nmask = ~np.isnan(functional_gradients[:, 0]) & ~np.isnan(tstat)\nr_empirical = np.corrcoef(functional_gradients[mask, 0], tstat[mask])[0, 1]\nr_permuted = np.zeros(n_rep)\nfor i in range(n_rep):\n    mask = ~np.isnan(functional_gradients[:, 0]) & ~np.isnan(tstat_rotated[i, :])\n    r_permuted[i] = np.corrcoef(functional_gradients[mask, 0], tstat_rotated[i, mask])[\n        1:, 0\n    ]\n\n# Significance depends on whether we do a one-tailed or two-tailed test.\n# If one-tailed it depends on in which direction the test is.\np_value_right_tailed = np.mean(r_empirical > r_permuted)\np_value_left_tailed = np.mean(r_empirical < r_permuted)\np_value_two_tailed = np.minimum(p_value_right_tailed, p_value_left_tailed) * 2\nprint(f\"Two tailed p-value: {p_value_two_tailed}\")\n\n# Plot the permuted distribution of correlations.\nplt.hist(r_permuted, bins=20, color=\"c\", edgecolor=\"k\", alpha=0.65)\nplt.axvline(r_empirical, color=\"k\", linestyle=\"dashed\", linewidth=1)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see from both the p-value as well as the histogram, wherein the\ndotted line denotes the empirical correlation, this correlation does not reach\nsignificance.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decoding without statistics module - mean thickness\n---------------------\nIt is fully possible to also run context decoding on maps that do not per se\ncome from the statistics module of brainstat. In example below, we decode\nthe mean cortical thickness map of our participants\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "meta_analysis = meta_analytic_decoder(\"fsaverage5\", np.mean(thickness, axis=0))\nprint(meta_analysis)\n\nwc = WordCloud(background_color=\"white\", random_state=0)\nwc.generate_from_frequencies(frequencies=meta_analysis.to_dict()[\"Pearson's r\"])\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decoding without statistics module - decoding nilearn results\n---------------------\nIt is equally possible to run context decoding on maps derived from e.g.\nnilearn. In the example below, we decode task-fmri results from nilearn\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_language_localizer_demo_dataset\n\ndata_dir, _ = fetch_language_localizer_demo_dataset()\n\nfrom nilearn.glm.first_level import first_level_from_bids\n\ntask_label = \"languagelocalizer\"\n_, models_run_imgs, models_events, models_confounds = first_level_from_bids(\n    data_dir, task_label, img_filters=[(\"desc\", \"preproc\")]\n)\n\n# obtain first level Model objects and arguments\nfrom nilearn.glm.first_level import first_level_from_bids\n\ntask_label = \"languagelocalizer\"\n_, models_run_imgs, models_events, models_confounds = first_level_from_bids(\n    data_dir, task_label, img_filters=[(\"desc\", \"preproc\")]\n)\n\nimport os\n\njson_file = os.path.join(\n    data_dir,\n    \"derivatives\",\n    \"sub-01\",\n    \"func\",\n    \"sub-01_task-languagelocalizer_desc-preproc_bold.json\",\n)\nimport json\n\nwith open(json_file, \"r\") as f:\n    t_r = json.load(f)[\"RepetitionTime\"]\n\n# project onto fsaverage\nfrom nilearn.datasets import fetch_surf_fsaverage\n\nfsa = fetch_surf_fsaverage(mesh=\"fsaverage5\")\n\nimport numpy as np\nfrom nilearn import surface\nfrom nilearn.glm.first_level import make_first_level_design_matrix\nfrom nilearn.glm.first_level import run_glm\nfrom nilearn.glm.contrasts import compute_contrast\n\nz_scores_right = []\nz_scores_left = []\nfor (fmri_img, confound, events) in zip(\n    models_run_imgs, models_confounds, models_events\n):\n    texture = surface.vol_to_surf(fmri_img[0], fsa.pial_right)\n    n_scans = texture.shape[1]\n    frame_times = t_r * (np.arange(n_scans) + 0.5)\n\n    # Create the design matrix\n    #\n    # We specify an hrf model containing Glover model and its time derivative.\n    # The drift model is implicitly a cosine basis with period cutoff 128s.\n    design_matrix = make_first_level_design_matrix(\n        frame_times,\n        events=events[0],\n        hrf_model=\"glover + derivative\",\n        add_regs=confound[0],\n    )\n\n    # Contrast specification\n    contrast_values = (design_matrix.columns == \"language\") * 1.0 - (\n        design_matrix.columns == \"string\"\n    )\n\n    # Setup and fit GLM.\n    # Note that the output consists in 2 variables: `labels` and `fit`\n    # `labels` tags voxels according to noise autocorrelation.\n    # `estimates` contains the parameter estimates.\n    # We input them for contrast computation.\n    labels, estimates = run_glm(texture.T, design_matrix.values)\n    contrast = compute_contrast(labels, estimates, contrast_values, contrast_type=\"t\")\n    # We present the Z-transform of the t map.\n    z_score = contrast.z_score()\n    z_scores_right.append(z_score)\n\n    # Do the left hemisphere exactly the same way.\n    texture = surface.vol_to_surf(fmri_img, fsa.pial_left)\n    labels, estimates = run_glm(texture.T, design_matrix.values)\n    contrast = compute_contrast(labels, estimates, contrast_values, contrast_type=\"t\")\n    z_scores_left.append(contrast.z_score())\n\nfrom scipy.stats import ttest_1samp, norm\n\nt_left, pval_left = ttest_1samp(np.array(z_scores_left), 0)\nt_right, pval_right = ttest_1samp(np.array(z_scores_right), 0)\n\nz_val_left = norm.isf(pval_left)\nz_val_right = norm.isf(pval_right)\n\n# and then do a similar decoding on the z_val vectors\nmap = np.concatenate([z_val_left, z_val_right])\nmeta_analysis = meta_analytic_decoder(\"fsaverage5\", map)\nprint(meta_analysis)\n\nwc = WordCloud(background_color=\"white\", random_state=0)\nwc.generate_from_frequencies(frequencies=meta_analysis.to_dict()[\"Pearson's r\"])\nplt.imshow(wc)\nplt.axis(\"off\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That concludes the tutorials of BrainStat. If anything is unclear, or if you\nthink you've found a bug, please post it to the Issues page of our Github.\n\nHappy BrainStating!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}