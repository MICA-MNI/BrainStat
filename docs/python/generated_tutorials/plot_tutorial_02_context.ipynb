{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial 02: Context Decoding\n\nIn this tutorial you will learn about the context decoding tools included with\nBrainStat. The context decoding module consists of three parts: genetic\ndecoding, meta-analytic decoding and histological comparisons. First, we'll\nconsider how to run the genetic decoding analysis. \n\n\n## Genetics\n\nFor genetic decoding we use the Allen Human Brain Atlas through the abagen\ntoolbox. Note that abagen only accepts parcellated data. Here is a minimal\nexample of how we use abagen to get the genetic expression of the regions of the\nDestrieux atlas. Please note that downloading the dataset and running this\nanalysis can take several minutes. As such, we will not run the analysis here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom brainstat.context.genetics import surface_genetic_expression\nfrom nilearn import datasets\n\nrun_analysis = False  # Too resource intensive to run on ReadTheDocs\n\ndestrieux = datasets.fetch_atlas_surf_destrieux()\nlabels = np.hstack((destrieux[\"map_left\"], destrieux[\"map_right\"]))\nfsaverage = datasets.fetch_surf_fsaverage()\nsurfaces_pial = [fsaverage[\"pial_left\"], fsaverage[\"pial_right\"]]\n\nif run_analysis:\n    expression = surface_genetic_expression(labels, surfaces_pial, space=\"fsaverage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Expression is a pandas DataFrame which shows the genetic expression of genes\nwithin each region of the atlas. By default, the values will fall in the range\n[0, 1] where higher values represent higher expression. However, if you change\nthe normalization function then this may change. Some regions may return NaN\nvalues for all modules. This occurs when there are no samples within this region\nacross all donors.\n\nBy default, BrainStat uses all the default abagen parameters. If you wish to\ncustomize these parameters then the keyword arguments can be passed directly to\n`surface_genetic_expression`. For a full list of these arguments and their\nfunction please consult the abagen documentation.\n\n## Meta-Analytic\nTo perform meta-analytic decoding, BrainStat interfaces with NiMare. Here we\ntest which terms are most associated with a map of cortical thickness. A simple example\nanalysis can be run as follows. First, we will load some cortical thickness data and\nthe white matter surface (recall that we've already loaded the pial surface).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport brainstat\nimport nibabel as nib\nfrom brainstat.context.meta_analysis import surface_decoder\nfrom brainstat.tutorial.utils import fetch_tutorial_data\n\n## Load white matter surfaces.\nsurfaces_white = [fsaverage[\"white_left\"], fsaverage[\"white_right\"]]\n\n## Load cortical thickness data.\n# Note: you can change the data_dir to wherever you'd like to save the data.\nbrainstat_dir = os.path.dirname(brainstat.__file__)\ndata_dir = os.path.join(brainstat_dir, \"tutorial\")\n\nn = 20\ntutorial_data = fetch_tutorial_data(n_subjects=n, data_dir=data_dir)\n\n# Reshape the thickness files such that left and right hemispheres are in the same row.\nfiles = np.reshape(np.array(tutorial_data[\"image_files\"]), (-1, 2))\n\n# We'll use only the left hemisphere in this tutorial.\nsubject_thickness = np.zeros((n, 20484))\nfor i in range(n):\n    left_thickness = np.squeeze(nib.load(files[i, 0]).get_fdata())\n    right_thickness = np.squeeze(nib.load(files[i, 1]).get_fdata())\n    subject_thickness[i, :] = np.concatenate((left_thickness, right_thickness))\n\nthickness = np.mean(subject_thickness, axis=0)\nmask = np.all(subject_thickness != 0, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we can run the analysis. Note that the data and mask has to be\nprovided seperately for each hemisphere.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if run_analysis:\n    meta_analysis = surface_decoder(\n        surfaces_pial,\n        surfaces_white,\n        [thickness[:10242], thickness[10242:]],\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "meta_analysis now contains a pandas.dataFrame with the correlation values\nfor each requested feature.\n\n## Histological decoding\nFor histological decoding we use microstructural profile covariance gradients\ncomputed from the BigBrain dataset. (TODO: Add more background). Firstly, lets\ndownload the MPC data and compute its gradients. As the computations for this aren't\nvery intesnive, we can actually run this on ReadTheDocs!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainspace.datasets import load_parcellation\nfrom brainstat.context.histology import (\n    compute_histology_gradients,\n    compute_mpc,\n    read_histology_profile,\n)\n\n# Load the Schaefer 400 atlas\nschaefer_400 = load_parcellation(\"schaefer\", scale=400, join=True)\n\n# Run the analysis\nhistology_profiles = read_histology_profile(template=\"fs_LR_64k\")\nmpc = compute_mpc(histology_profiles, labels=schaefer_400)\ngradient_map = compute_histology_gradients(mpc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot the first gradient of histology to see what it looks like.\nWe will use BrainSpace to create our plots. For full details on how\nBrainSpace's plotting functionality works, please consult the BrainSpace\nReadTheDocs. (NOTE: Temporarily disabled due to build errors)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from brainspace.datasets import load_conte69\nfrom brainspace.plotting.surface_plotting import plot_hemispheres\nfrom brainspace.utils.parcellation import map_to_labels\n\nleft_surface, right_surface = load_conte69()\nvertexwise_data = []\nfor i in range(0, 2):\n    vertexwise_data.append(\n        map_to_labels(\n            gradient_map.gradients_[:, i],\n            schaefer_400,\n            mask=schaefer_400 != 0,\n            fill=np.nan,\n        )\n    )\n# plot_hemispheres(left_surface, right_surface, vertexwise_data, embed_nb=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}